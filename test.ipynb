{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9a01d91c-3988-4170-8672-112031895dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import test\n",
    "from utils.data_utils import get_loader\n",
    "from models_swin.ms_swin_transformer import *\n",
    "from models_swin.swin_transformer import SwinTransformer\n",
    "import models_swin.ms_backup as ms_b\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# from visual import featuremap\n",
    "import visual\n",
    "import timm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69c30d64-d386-4cd6-979f-6c1082ef9e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "args=test.parse_option()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58245bc4-495a-43e9-ab77-5f2ea9be2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data\n",
    "_, test_loader = get_loader(args)\n",
    "# train_list = list(enumerate(train_loader))\n",
    "test_list = list(enumerate(test_loader))\n",
    "\n",
    "# for i in range(0,3):\n",
    "img, label = next(iter(test_loader))\n",
    "\n",
    "plt.imshow(img[0,:].permute(1,2,0).detach().cpu().numpy())\n",
    "# plt.imshow(test_loader.dataset.test_img[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b93d3846-7131-4e6f-b5a6-9a413b70b372",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model\n",
    "# model_ckpt = torch.load('output/sample_run_swin_t_no_checkpoint.bin')\n",
    "model_ckpt = torch.load('output/ms_sample_run_swin_t_no_check_checkpoint.bin')\n",
    "\n",
    "model=MSSwinTransformer(img_size=448, num_classes=200, num_feature_layers=1, detail_features=True)\n",
    "# model=SwinTransformer(img_size=448, num_classes=200)\n",
    "# model=ms_b.MSSwinTransformer(img_size=448, num_classes=200)\n",
    "model.load_state_dict(model_ckpt['model'], strict=False)\n",
    "model.eval()\n",
    "# x=torch.randn((16,3,448,448))\n",
    "x = test_list[0][1][0]\n",
    "f=model.forward_features(x)\n",
    "logits=model(x)\n",
    "# f.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de0940-01be-4d44-abee-92aaaab52bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multi-layer feature map\n",
    "layers = [2, 2, 6, 2]\n",
    "lf = model.layer_features\n",
    "vv=[]\n",
    "for i in range(len(layers)):\n",
    "    for j in range(layers[i]):\n",
    "        stage = i\n",
    "        block = j\n",
    "        edge=6\n",
    "        corr,f = visual.featuremap(lf[stage][block], num_batch=0, edge=edge, start_ch=0)\n",
    "        s,v,d = np.linalg.svd(corr)\n",
    "        vv.append(v)\n",
    "        plt.figure()\n",
    "        plt.suptitle('stage={0},block={1}'.format(stage, block), fontsize=14)\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(corr)    \n",
    "        plt.title(\"channel correlation\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(f)\n",
    "        plt.title(\"feature map\")\n",
    "        \n",
    "        \n",
    "        # plt.colorbar()\n",
    "#         plt.savefig('./visual/stage={0}_block={1}_edge{2}.png'.format(stage,block,edge),dpi=300)\n",
    "        plt.show()                                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de46957d-f430-4f0c-91c0-b8f4f7c32fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=3\n",
    "b=-1\n",
    "plt.imshow(lf[s][b].mean(2).view(-1,int(112/2**s),int(112/2**s)).detach()[5,:,:])\n",
    "lf[3][1].shape\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c79376-adf2-4661-be5d-a19262f6b434",
   "metadata": {},
   "outputs": [],
   "source": [
    "## logits\n",
    "# s=torch.nn.Sigmoid()(logits)\n",
    "# sd=s.detach()\n",
    "# plt.plot(sd[1,:])\n",
    "plt.plot(logits[2,:].detach())\n",
    "print(torch.argmax(logits[2,:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45fb8c6b-dd5b-4802-a9da-8d6d6eff2b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tl=iter(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd346ae-81d1-4da4-b594-6983e478d06f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c995bcae-3f1d-4fac-8c07-750c75bc49f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CAM\n",
    "\n",
    "from pytorch_grad_cam import GradCAM, \\\n",
    "                             ScoreCAM, \\\n",
    "                             GradCAMPlusPlus, \\\n",
    "                             AblationCAM, \\\n",
    "                             XGradCAM, \\\n",
    "                             EigenCAM, \\\n",
    "                             EigenGradCAM\n",
    "\n",
    "from pytorch_grad_cam import GuidedBackpropReLUModel\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image, \\\n",
    "                                         deprocess_image, \\\n",
    "                                         preprocess_image\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c948152-2b1c-407c-bd1c-1ea4239bb490",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img[0,:].permute(1,2,0).detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df31768-04b2-44b0-b4b2-ea34fcaab5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('models_swin/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6882ed42-b56e-4910-aa04-cc76e6ee307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join('models_swin/', 'ms_backup.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02022e3c-e3d7-4dfc-94f6-7adbcf5b3c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "test_loader.dataset[32][1]\n",
    "labels=[test_loader.dataset[i][1] for i in range(len(test_loader.dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b141c340-80f7-4686-9958-d5e59e3013b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45b9e87-8c3a-461f-8d5c-694b689bfcd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23902e9a-c18f-467f-906e-55bd4c73b8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confusion matrix\n",
    "pred = np.load('confusion_base.npy')\n",
    "conf=np.zeros((200,200))\n",
    "for n, i in enumerate(labels):\n",
    "    j = np.argmax(pred[n])\n",
    "    conf[i][j]+=1\n",
    "    \n",
    "plt.figure(dpi=300)\n",
    "plt.imshow((conf.T/conf.sum(1)).T)\n",
    "plt.colorbar()\n",
    "plt.title('confusion matrix(swin_base)')\n",
    "plt.xlabel('pred')\n",
    "plt.ylabel('label')\n",
    "plt.savefig('confusion_matrix_base.png',dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ad8327-5957-4d73-88f9-bb5a20a0881d",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf.trace()/conf.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83b9d57-bd10-4f11-be2f-6e08b4cbc704",
   "metadata": {},
   "outputs": [],
   "source": [
    "s=3\n",
    "H = int(112/2**s)\n",
    "plt.figure()\n",
    "for b in range(2):\n",
    "    plt.subplot(2,1,b+1)\n",
    "    feature=lf[s][b]\n",
    "    feature=feature.mean(2).squeeze()\n",
    "    vv=feature.view(8,H,H)\n",
    "    plt.imshow(vv[7])\n",
    "    plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef587e6c-8e5a-454b-b722-206997ab28df",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature=lf[2][1]\n",
    "feature=feature.mean(2).squeeze()\n",
    "vv=feature.view(8,28,28)\n",
    "plt.imshow(vv[7])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99369b12-39de-4415-b60a-750e31248cea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(vv)):\n",
    "    plt.figure()\n",
    "    plt.plot(vv[i])\n",
    "    print(vv[i][50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a6d9f8d-f73f-4d3f-9d3f-d5664be5cf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aff import fusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ecaf3b89-1417-4d6f-853e-20ed0814cce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.8575,  0.8771, -0.4475, -1.9260, -0.0536],\n",
      "         [-0.1054, -2.0634, -1.3432, -0.9708, -0.5831],\n",
      "         [ 0.6183,  0.6156,  1.3839, -1.0138, -1.6934],\n",
      "         [ 0.6169, -1.2540,  0.6231,  1.3413, -0.0665],\n",
      "         [ 0.4537,  0.0672,  0.6152,  0.9737,  1.5877]],\n",
      "\n",
      "        [[ 0.1877, -0.0726,  0.9181, -1.3993, -0.1569],\n",
      "         [ 1.1534, -0.9384,  0.3260,  0.4129,  0.9172],\n",
      "         [-0.7366, -0.9122,  0.2868, -0.5730, -0.5904],\n",
      "         [-1.1469,  0.3358,  0.1498,  0.1514,  0.4370],\n",
      "         [ 1.3599, -0.5992,  0.1621,  0.3121,  0.6999]],\n",
      "\n",
      "        [[-0.1285,  0.1215,  0.6114, -0.5164,  0.8864],\n",
      "         [ 1.5016,  0.0780, -0.7000, -0.3608, -0.9741],\n",
      "         [-1.4275,  1.6934,  0.1261,  0.1998,  1.8123],\n",
      "         [-0.5990, -0.8963,  1.7971, -0.3297,  0.7304],\n",
      "         [-0.4662,  0.3959, -0.8960,  0.3101, -0.6885]]])\n",
      "tensor([[ 0.0207, -0.0077, -0.2512, -1.3918,  0.0075],\n",
      "        [-0.1825,  0.1510,  0.3065,  0.1446,  0.5210],\n",
      "        [ 0.6501, -0.9510,  0.0501,  0.1161,  1.8118],\n",
      "        [ 0.4238,  0.3775,  0.1678, -0.0670, -0.0212],\n",
      "        [-0.2876, -0.0159, -0.0894,  0.0942, -0.7651]])\n",
      "tensor([[0.2745,    nan,    nan,    nan, 0.1954],\n",
      "        [   nan, 0.5325, 0.6743, 0.5249, 0.8047],\n",
      "        [0.8663,    nan, 0.3685, 0.4878, 1.2191],\n",
      "        [0.7512, 0.7227, 0.5515,    nan,    nan],\n",
      "        [   nan,    nan,    nan, 0.4550,    nan]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn((3,5,5))\n",
    "print(a)\n",
    "print(a.prod(0))\n",
    "print(a.prod(0)**(1/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "12dd3ea7-ef9c-41df-8be5-d97124d3a106",
   "metadata": {},
   "outputs": [],
   "source": [
    "aff=fusion.AFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a9f4f943-3dec-4320-8ff8-688a233de609",
   "metadata": {},
   "outputs": [],
   "source": [
    "tb=torch.utils.tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2789797a-0b9e-41c2-b44b-712fc8f8d3ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['FileWriter',\n",
       " 'RecordWriter',\n",
       " 'SummaryWriter',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_convert_np',\n",
       " '_embedding',\n",
       " '_onnx_graph',\n",
       " '_proto_graph',\n",
       " '_pytorch_graph',\n",
       " '_utils',\n",
       " 'summary',\n",
       " 'writer']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8d78356-692a-478a-98db-0cbce9d7a814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "a=torch.randn((1,3,10,10))\n",
    "b=torch.nn.AdaptiveAvgPool2d(1)(a)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7f82b065-cd3c-405d-9582-9064a63d1425",
   "metadata": {},
   "outputs": [],
   "source": [
    "a=torch.nn.Parameter(torch.Tensor(1,2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d9d8e43-b62c-4ec0-86af-57cafb5a4d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">3\n"
     ]
    }
   ],
   "source": [
    "a=10\n",
    "if a>3:\n",
    "    print('>3')\n",
    "elif a>1:\n",
    "    print('>1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e039ef-4088-4d23-9fc1-c90091a98499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
